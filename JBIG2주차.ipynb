{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기본 베이스라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# StratifiedShuffleSplit을 사용하여 데이터를 분할합니다.\n",
    "# stratified_shuffle_split = StratifiedShuffleSplit(n_splits=20, test_size=0.3, random_state=1)\n",
    "\n",
    "#stratifiedKfold 교차검증\n",
    "# 데이터 불러오기\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "submit = pd.read_csv('sample_submission.csv')\n",
    "# 전처리\n",
    "# 훈련 및 테스트 세트 모두에서 'ID' 열을 삭제하세요. 학습에 불필요한 칼럼입니다.\n",
    "train = train.drop(['ID'], axis = 1)\n",
    "test = test.drop(['ID'],axis = 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_460853/21238768.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train.SkinThickness[train.SkinThickness==0]=train.SkinThickness[train.SkinThickness!=0].mean()\n",
      "/tmp/ipykernel_460853/21238768.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train.Insulin[train.Insulin==0]=train.Insulin[train.Insulin!=0].mean()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# train전처리\n",
    "#1.(스킨를 평균)\n",
    "\n",
    "train.SkinThickness[train.SkinThickness==0]=train.SkinThickness[train.SkinThickness!=0].mean()\n",
    "\n",
    " #2.(인슐린를 평균)\n",
    "train.Insulin[train.Insulin==0]=train.Insulin[train.Insulin!=0].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_460853/3200531208.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test.SkinThickness[test.SkinThickness==0]=test.SkinThickness[test.SkinThickness!=0].mean()\n",
      "/tmp/ipykernel_460853/3200531208.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test.Insulin[test.Insulin==0]=test.Insulin[test.Insulin!=0].mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.81651376, 0.75229358, 0.71559633, 0.71559633, 0.74074074,\n",
       "       0.75925926])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    " #4.(BloodPressure를 정규화)\n",
    "bbb=train.BloodPressure.max()-train.BloodPressure.min()\n",
    "aaa=train.BloodPressure-train.BloodPressure.min()\n",
    "ccc=aaa/bbb\n",
    "train.BloodPressure=ccc\n",
    "\n",
    " #5.(BMI를 정규화)\n",
    "bbb=train.BMI.max()-train.BMI.min()\n",
    "aaa=train.BMI-train.BMI.min()\n",
    "ccc=aaa/bbb\n",
    "train.BMI=ccc\n",
    " #6.(Glucose를 정규화)\n",
    "bbb=train.Glucose.max()-train.Glucose.min()\n",
    "aaa=train.Glucose-train.Glucose.min()\n",
    "ccc=aaa/bbb\n",
    "train.Glucose=ccc\n",
    "\n",
    "#test 전처리\n",
    "#1.(스킨를 평균)\n",
    "test.SkinThickness[test.SkinThickness==0]=test.SkinThickness[test.SkinThickness!=0].mean()\n",
    "\n",
    " #2.(인슐린를 평균)\n",
    "test.Insulin[test.Insulin==0]=test.Insulin[test.Insulin!=0].mean()\n",
    "\n",
    "\n",
    " #4.(BloodPressure를 정규화)\n",
    "bbb=test.BloodPressure.max()-test.BloodPressure.min()\n",
    "aaa=test.BloodPressure-test.BloodPressure.min()\n",
    "ccc=aaa/bbb\n",
    "test.BloodPressure=ccc\n",
    "\n",
    " #5.(BMI를 정규화)\n",
    "bbb=test.BMI.max()-test.BMI.min()\n",
    "aaa=test.BMI-test.BMI.min()\n",
    "ccc=aaa/bbb\n",
    "test.BMI=ccc\n",
    " #6.(Glucose를 정규화)\n",
    "bbb=test.Glucose.max()-test.Glucose.min()\n",
    "aaa=test.Glucose-test.Glucose.min()\n",
    "ccc=aaa/bbb\n",
    "test.Glucose=ccc\n",
    "\n",
    "\n",
    "# Train set을 독립변수(X)와 종속변수(y)로 나누세요\n",
    "X = train.drop('Outcome', axis =1)\n",
    "y = train['Outcome']\n",
    "# sklearn의 train_test_split을 사용하여 Train set와 Test set으로 분할하세요\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.3)\n",
    "\n",
    "\n",
    "# 모델 정의 및 학습\n",
    "# sklearn의 RandomForestClassifier를 정의하고 Train set에 대해 학습해세요\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "# 1. 모델 초기화\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100, # 트리의 개수\n",
    "                                             random_state=42)  # 결과의 재현성을 위한 랜덤 시드 설정\n",
    "\n",
    "kfold=  KFold(n_splits=6,shuffle=True,random_state=1)\n",
    "scores =cross_val_score(random_forest_model, X,y,cv=kfold)\n",
    "\n",
    "np.round(scores,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7091836734693877\n",
      "Cross-validated scores: [0.7544 0.7719 0.7193 0.7632]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "import numpy as np\n",
    "\n",
    "# 데이터 정규화\n",
    "# Logistic Regression 모델 초기화\n",
    "logistic_regression_model = LogisticRegression(solver='newton-cg',max_iter=600) #'liblinear', 'newton-cg', 'sag', 'saga'\n",
    "\n",
    "# Train set에 대해 모델 학습\n",
    "logistic_regression_model.fit(X_train, y_train)\n",
    "\n",
    "# Test set에 대한 예측 및 정확도 평가\n",
    "accuracy = logistic_regression_model.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# KFold 교차 검증을 통한 모델 성능 평가\n",
    "kfold = KFold(n_splits=4, shuffle=True, random_state=1)\n",
    "scores = cross_val_score(logistic_regression_model, X_train, y_train, cv=kfold)\n",
    "\n",
    "# 교차 검증 결과 출력\n",
    "print(\"Cross-validated scores:\", np.round(scores, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test = logistic_regression_model.predict(test)\n",
    "submit['Outcome'] = y_test\n",
    "\n",
    "submit\n",
    "\n",
    "submit.to_csv('abcde.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'solver' parameter of LogisticRegression must be a str among {'liblinear', 'saga', 'sag', 'lbfgs', 'newton-cholesky', 'newton-cg'}. Got ['lbfgs', 'liblinear', 'newton-cg', 'sag', 'saga'] instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 2. 모델 학습\u001b[39;00m\n\u001b[1;32m      2\u001b[0m random_forest_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m----> 3\u001b[0m model1\u001b[38;5;241m.\u001b[39mfit(X_train,y_train)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 3. 테스트 데이터에 대한 예측\u001b[39;00m\n\u001b[1;32m      5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model1\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1144\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m partial_fit_and_fitted \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1140\u001b[0m     fit_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[1;32m   1141\u001b[0m )\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[0;32m-> 1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:637\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    630\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \n\u001b[1;32m    632\u001b[0m \u001b[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;124;03m    accepted constraints.\u001b[39;00m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 637\u001b[0m     validate_parameter_constraints(\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parameter_constraints,\n\u001b[1;32m    639\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m    640\u001b[0m         caller_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[1;32m    641\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:95\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m     )\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'solver' parameter of LogisticRegression must be a str among {'liblinear', 'saga', 'sag', 'lbfgs', 'newton-cholesky', 'newton-cg'}. Got ['lbfgs', 'liblinear', 'newton-cg', 'sag', 'saga'] instead."
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. 모델 학습\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "model1.fit(X_train,y_train)\n",
    "# 3. 테스트 데이터에 대한 예측\n",
    "y_pred = model1.predict(X_test)\n",
    "\n",
    "# 4. 모델의 정확도 평가\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "\n",
    "\n",
    "# 모델 예측\n",
    "# Test set에서 예측을 수행하세요\n",
    "y_test = random_forest_model.predict(test)\n",
    "submit['Outcome'] = y_test\n",
    "\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('abcd.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n",
      "/root/anaconda3/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but DecisionTreeClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Random Forest 모델을 훈련합니다.\n",
    "random_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# 각 트리에서 예측한 클래스 확률을 수집합니다.\n",
    "class_probabilities = np.zeros((len(X_test), len(random_forest_model.classes_)))\n",
    "for tree in random_forest_model.estimators_:\n",
    "    class_probabilities += tree.predict_proba(X_test)\n",
    "\n",
    "# 모든 트리의 확률을 평균화합니다.\n",
    "class_probabilities /= len(random_forest_model.estimators_)\n",
    "\n",
    "# 가장 높은 평균 확률을 갖는 클래스를 최종 예측으로 선택합니다.\n",
    "final_predictions = np.argmax(class_probabilities, axis=1)\n",
    "\n",
    "# 이제 final_predictions에는 소프트 보팅을 사용하여 예측된 클래스가 포함되어 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 순서\n",
    "\n",
    "\n",
    "스케일러 -> 교차검증 -> 그리드서치 -> 배깅"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 코드에서 스케일러를 추가해보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일러에는 여러 종류가 있습니다. 다른 스케일러를 하나 더 구현해보세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation(cv) ; 교차검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 코드에서 train_test_split이 아닌 cross_val_score 을 통해 성능을 올려보세요. (StratifiedKFold 제외)\n",
    "# cv_scores와 cv_scores 의 평균을 출력해보세요\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 코드에서 StratifiedKFold를 추가하여 데이터 불균형을 해소해보세요\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearch ; 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그리드 서치를 통해서 모델의 하이퍼파라미터들을 효과적으로 최적화해보세요.\n",
    "# 최적의 파라미터들을 출력해보세요(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공식 Document(예. sklearn RandomForestClassifier)을 참고해서 더 많은 하이퍼 파라미터와 범위를 추가해보세요.\n",
    "# 이 부분은 GPT보다도 직접 찾아보는게 더 공부가 될거에요."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앙상블 ; 배깅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그리드처리를 통해 도출된 최적의 모델에 앙상블 기법 중 배깅을 활용해서 성능을 향상시켜보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML ; PyCaret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyCaret 공식 Document 중 QuickStart에 들어가시면 상세하게 잘 설명되어있습니다.\n",
    "\n",
    "당뇨병 데이터를 넣어서 PyCaret을 사용해보세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f2684_row8_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f2684\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f2684_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_f2684_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f2684_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f2684_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_f2684_row0_col1\" class=\"data row0 col1\" >3721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2684_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f2684_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_f2684_row1_col1\" class=\"data row1 col1\" >Outcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2684_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f2684_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_f2684_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2684_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f2684_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_f2684_row3_col1\" class=\"data row3 col1\" >(652, 9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2684_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f2684_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_f2684_row4_col1\" class=\"data row4 col1\" >(652, 9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2684_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_f2684_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_f2684_row5_col1\" class=\"data row5 col1\" >(456, 9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2684_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_f2684_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_f2684_row6_col1\" class=\"data row6 col1\" >(196, 9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2684_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_f2684_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_f2684_row7_col1\" class=\"data row7 col1\" >8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2684_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_f2684_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_f2684_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2684_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_f2684_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_f2684_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2684_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_f2684_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_f2684_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2684_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_f2684_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_f2684_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2684_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_f2684_row12_col0\" class=\"data row12 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_f2684_row12_col1\" class=\"data row12 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2684_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_f2684_row13_col0\" class=\"data row13 col0\" >Fold Number</td>\n",
       "      <td id=\"T_f2684_row13_col1\" class=\"data row13 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2684_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_f2684_row14_col0\" class=\"data row14 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_f2684_row14_col1\" class=\"data row14 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2684_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_f2684_row15_col0\" class=\"data row15 col0\" >Use GPU</td>\n",
       "      <td id=\"T_f2684_row15_col1\" class=\"data row15 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2684_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_f2684_row16_col0\" class=\"data row16 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_f2684_row16_col1\" class=\"data row16 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2684_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_f2684_row17_col0\" class=\"data row17 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_f2684_row17_col1\" class=\"data row17 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2684_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_f2684_row18_col0\" class=\"data row18 col0\" >USI</td>\n",
       "      <td id=\"T_f2684_row18_col1\" class=\"data row18 col1\" >6440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc5cf3a7640>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_aafc2 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_aafc2_row0_col0, #T_aafc2_row0_col2, #T_aafc2_row0_col3, #T_aafc2_row0_col4, #T_aafc2_row1_col0, #T_aafc2_row1_col2, #T_aafc2_row1_col3, #T_aafc2_row1_col5, #T_aafc2_row1_col6, #T_aafc2_row1_col7, #T_aafc2_row2_col0, #T_aafc2_row2_col3, #T_aafc2_row2_col5, #T_aafc2_row2_col6, #T_aafc2_row2_col7, #T_aafc2_row3_col0, #T_aafc2_row3_col1, #T_aafc2_row3_col2, #T_aafc2_row3_col3, #T_aafc2_row3_col4, #T_aafc2_row3_col5, #T_aafc2_row3_col6, #T_aafc2_row3_col7, #T_aafc2_row4_col0, #T_aafc2_row4_col1, #T_aafc2_row4_col2, #T_aafc2_row4_col3, #T_aafc2_row4_col4, #T_aafc2_row4_col5, #T_aafc2_row4_col6, #T_aafc2_row4_col7, #T_aafc2_row5_col0, #T_aafc2_row5_col1, #T_aafc2_row5_col2, #T_aafc2_row5_col3, #T_aafc2_row5_col4, #T_aafc2_row5_col5, #T_aafc2_row5_col6, #T_aafc2_row5_col7, #T_aafc2_row6_col0, #T_aafc2_row6_col1, #T_aafc2_row6_col2, #T_aafc2_row6_col4, #T_aafc2_row6_col5, #T_aafc2_row6_col6, #T_aafc2_row6_col7, #T_aafc2_row7_col0, #T_aafc2_row7_col1, #T_aafc2_row7_col2, #T_aafc2_row7_col3, #T_aafc2_row7_col4, #T_aafc2_row7_col5, #T_aafc2_row7_col6, #T_aafc2_row7_col7, #T_aafc2_row8_col0, #T_aafc2_row8_col1, #T_aafc2_row8_col2, #T_aafc2_row8_col3, #T_aafc2_row8_col4, #T_aafc2_row8_col5, #T_aafc2_row8_col6, #T_aafc2_row8_col7, #T_aafc2_row9_col0, #T_aafc2_row9_col1, #T_aafc2_row9_col2, #T_aafc2_row9_col3, #T_aafc2_row9_col4, #T_aafc2_row9_col5, #T_aafc2_row9_col6, #T_aafc2_row9_col7, #T_aafc2_row10_col0, #T_aafc2_row10_col1, #T_aafc2_row10_col2, #T_aafc2_row10_col3, #T_aafc2_row10_col4, #T_aafc2_row10_col5, #T_aafc2_row10_col6, #T_aafc2_row10_col7, #T_aafc2_row11_col0, #T_aafc2_row11_col1, #T_aafc2_row11_col2, #T_aafc2_row11_col3, #T_aafc2_row11_col4, #T_aafc2_row11_col5, #T_aafc2_row11_col6, #T_aafc2_row11_col7, #T_aafc2_row12_col0, #T_aafc2_row12_col1, #T_aafc2_row12_col2, #T_aafc2_row12_col3, #T_aafc2_row12_col4, #T_aafc2_row12_col5, #T_aafc2_row12_col6, #T_aafc2_row12_col7, #T_aafc2_row13_col0, #T_aafc2_row13_col1, #T_aafc2_row13_col2, #T_aafc2_row13_col3, #T_aafc2_row13_col4, #T_aafc2_row13_col5, #T_aafc2_row13_col6, #T_aafc2_row13_col7, #T_aafc2_row14_col0, #T_aafc2_row14_col1, #T_aafc2_row14_col2, #T_aafc2_row14_col3, #T_aafc2_row14_col4, #T_aafc2_row14_col5, #T_aafc2_row14_col6, #T_aafc2_row14_col7, #T_aafc2_row15_col0, #T_aafc2_row15_col1, #T_aafc2_row15_col2, #T_aafc2_row15_col3, #T_aafc2_row15_col4, #T_aafc2_row15_col5, #T_aafc2_row15_col6, #T_aafc2_row15_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_aafc2_row0_col1, #T_aafc2_row0_col5, #T_aafc2_row0_col6, #T_aafc2_row0_col7, #T_aafc2_row1_col1, #T_aafc2_row1_col4, #T_aafc2_row2_col1, #T_aafc2_row2_col2, #T_aafc2_row2_col4, #T_aafc2_row6_col3 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_aafc2_row0_col8, #T_aafc2_row1_col8, #T_aafc2_row2_col8, #T_aafc2_row3_col8, #T_aafc2_row4_col8, #T_aafc2_row5_col8, #T_aafc2_row6_col8, #T_aafc2_row7_col8, #T_aafc2_row8_col8, #T_aafc2_row9_col8, #T_aafc2_row10_col8, #T_aafc2_row11_col8, #T_aafc2_row12_col8, #T_aafc2_row13_col8, #T_aafc2_row14_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_aafc2_row15_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_aafc2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_aafc2_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_aafc2_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_aafc2_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_aafc2_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_aafc2_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_aafc2_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_aafc2_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_aafc2_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_aafc2_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_aafc2_level0_row0\" class=\"row_heading level0 row0\" >lr</th>\n",
       "      <td id=\"T_aafc2_row0_col0\" class=\"data row0 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_aafc2_row0_col1\" class=\"data row0 col1\" >0.7913</td>\n",
       "      <td id=\"T_aafc2_row0_col2\" class=\"data row0 col2\" >0.8303</td>\n",
       "      <td id=\"T_aafc2_row0_col3\" class=\"data row0 col3\" >0.6158</td>\n",
       "      <td id=\"T_aafc2_row0_col4\" class=\"data row0 col4\" >0.7480</td>\n",
       "      <td id=\"T_aafc2_row0_col5\" class=\"data row0 col5\" >0.6702</td>\n",
       "      <td id=\"T_aafc2_row0_col6\" class=\"data row0 col6\" >0.5206</td>\n",
       "      <td id=\"T_aafc2_row0_col7\" class=\"data row0 col7\" >0.5294</td>\n",
       "      <td id=\"T_aafc2_row0_col8\" class=\"data row0 col8\" >0.3910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aafc2_level0_row1\" class=\"row_heading level0 row1\" >ridge</th>\n",
       "      <td id=\"T_aafc2_row1_col0\" class=\"data row1 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_aafc2_row1_col1\" class=\"data row1 col1\" >0.7913</td>\n",
       "      <td id=\"T_aafc2_row1_col2\" class=\"data row1 col2\" >0.0000</td>\n",
       "      <td id=\"T_aafc2_row1_col3\" class=\"data row1 col3\" >0.6033</td>\n",
       "      <td id=\"T_aafc2_row1_col4\" class=\"data row1 col4\" >0.7532</td>\n",
       "      <td id=\"T_aafc2_row1_col5\" class=\"data row1 col5\" >0.6654</td>\n",
       "      <td id=\"T_aafc2_row1_col6\" class=\"data row1 col6\" >0.5174</td>\n",
       "      <td id=\"T_aafc2_row1_col7\" class=\"data row1 col7\" >0.5269</td>\n",
       "      <td id=\"T_aafc2_row1_col8\" class=\"data row1 col8\" >0.2030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aafc2_level0_row2\" class=\"row_heading level0 row2\" >lda</th>\n",
       "      <td id=\"T_aafc2_row2_col0\" class=\"data row2 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_aafc2_row2_col1\" class=\"data row2 col1\" >0.7913</td>\n",
       "      <td id=\"T_aafc2_row2_col2\" class=\"data row2 col2\" >0.8316</td>\n",
       "      <td id=\"T_aafc2_row2_col3\" class=\"data row2 col3\" >0.6033</td>\n",
       "      <td id=\"T_aafc2_row2_col4\" class=\"data row2 col4\" >0.7532</td>\n",
       "      <td id=\"T_aafc2_row2_col5\" class=\"data row2 col5\" >0.6654</td>\n",
       "      <td id=\"T_aafc2_row2_col6\" class=\"data row2 col6\" >0.5174</td>\n",
       "      <td id=\"T_aafc2_row2_col7\" class=\"data row2 col7\" >0.5269</td>\n",
       "      <td id=\"T_aafc2_row2_col8\" class=\"data row2 col8\" >0.2040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aafc2_level0_row3\" class=\"row_heading level0 row3\" >rf</th>\n",
       "      <td id=\"T_aafc2_row3_col0\" class=\"data row3 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_aafc2_row3_col1\" class=\"data row3 col1\" >0.7758</td>\n",
       "      <td id=\"T_aafc2_row3_col2\" class=\"data row3 col2\" >0.8194</td>\n",
       "      <td id=\"T_aafc2_row3_col3\" class=\"data row3 col3\" >0.6088</td>\n",
       "      <td id=\"T_aafc2_row3_col4\" class=\"data row3 col4\" >0.7152</td>\n",
       "      <td id=\"T_aafc2_row3_col5\" class=\"data row3 col5\" >0.6512</td>\n",
       "      <td id=\"T_aafc2_row3_col6\" class=\"data row3 col6\" >0.4887</td>\n",
       "      <td id=\"T_aafc2_row3_col7\" class=\"data row3 col7\" >0.4970</td>\n",
       "      <td id=\"T_aafc2_row3_col8\" class=\"data row3 col8\" >0.2360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aafc2_level0_row4\" class=\"row_heading level0 row4\" >gbc</th>\n",
       "      <td id=\"T_aafc2_row4_col0\" class=\"data row4 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_aafc2_row4_col1\" class=\"data row4 col1\" >0.7625</td>\n",
       "      <td id=\"T_aafc2_row4_col2\" class=\"data row4 col2\" >0.8227</td>\n",
       "      <td id=\"T_aafc2_row4_col3\" class=\"data row4 col3\" >0.5900</td>\n",
       "      <td id=\"T_aafc2_row4_col4\" class=\"data row4 col4\" >0.6867</td>\n",
       "      <td id=\"T_aafc2_row4_col5\" class=\"data row4 col5\" >0.6270</td>\n",
       "      <td id=\"T_aafc2_row4_col6\" class=\"data row4 col6\" >0.4565</td>\n",
       "      <td id=\"T_aafc2_row4_col7\" class=\"data row4 col7\" >0.4646</td>\n",
       "      <td id=\"T_aafc2_row4_col8\" class=\"data row4 col8\" >0.2100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aafc2_level0_row5\" class=\"row_heading level0 row5\" >qda</th>\n",
       "      <td id=\"T_aafc2_row5_col0\" class=\"data row5 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_aafc2_row5_col1\" class=\"data row5 col1\" >0.7605</td>\n",
       "      <td id=\"T_aafc2_row5_col2\" class=\"data row5 col2\" >0.8137</td>\n",
       "      <td id=\"T_aafc2_row5_col3\" class=\"data row5 col3\" >0.6204</td>\n",
       "      <td id=\"T_aafc2_row5_col4\" class=\"data row5 col4\" >0.6670</td>\n",
       "      <td id=\"T_aafc2_row5_col5\" class=\"data row5 col5\" >0.6375</td>\n",
       "      <td id=\"T_aafc2_row5_col6\" class=\"data row5 col6\" >0.4602</td>\n",
       "      <td id=\"T_aafc2_row5_col7\" class=\"data row5 col7\" >0.4646</td>\n",
       "      <td id=\"T_aafc2_row5_col8\" class=\"data row5 col8\" >0.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aafc2_level0_row6\" class=\"row_heading level0 row6\" >nb</th>\n",
       "      <td id=\"T_aafc2_row6_col0\" class=\"data row6 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_aafc2_row6_col1\" class=\"data row6 col1\" >0.7582</td>\n",
       "      <td id=\"T_aafc2_row6_col2\" class=\"data row6 col2\" >0.8173</td>\n",
       "      <td id=\"T_aafc2_row6_col3\" class=\"data row6 col3\" >0.6279</td>\n",
       "      <td id=\"T_aafc2_row6_col4\" class=\"data row6 col4\" >0.6690</td>\n",
       "      <td id=\"T_aafc2_row6_col5\" class=\"data row6 col5\" >0.6438</td>\n",
       "      <td id=\"T_aafc2_row6_col6\" class=\"data row6 col6\" >0.4616</td>\n",
       "      <td id=\"T_aafc2_row6_col7\" class=\"data row6 col7\" >0.4653</td>\n",
       "      <td id=\"T_aafc2_row6_col8\" class=\"data row6 col8\" >0.1920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aafc2_level0_row7\" class=\"row_heading level0 row7\" >et</th>\n",
       "      <td id=\"T_aafc2_row7_col0\" class=\"data row7 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_aafc2_row7_col1\" class=\"data row7 col1\" >0.7561</td>\n",
       "      <td id=\"T_aafc2_row7_col2\" class=\"data row7 col2\" >0.8017</td>\n",
       "      <td id=\"T_aafc2_row7_col3\" class=\"data row7 col3\" >0.5521</td>\n",
       "      <td id=\"T_aafc2_row7_col4\" class=\"data row7 col4\" >0.6862</td>\n",
       "      <td id=\"T_aafc2_row7_col5\" class=\"data row7 col5\" >0.6056</td>\n",
       "      <td id=\"T_aafc2_row7_col6\" class=\"data row7 col6\" >0.4343</td>\n",
       "      <td id=\"T_aafc2_row7_col7\" class=\"data row7 col7\" >0.4429</td>\n",
       "      <td id=\"T_aafc2_row7_col8\" class=\"data row7 col8\" >0.2230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aafc2_level0_row8\" class=\"row_heading level0 row8\" >catboost</th>\n",
       "      <td id=\"T_aafc2_row8_col0\" class=\"data row8 col0\" >CatBoost Classifier</td>\n",
       "      <td id=\"T_aafc2_row8_col1\" class=\"data row8 col1\" >0.7472</td>\n",
       "      <td id=\"T_aafc2_row8_col2\" class=\"data row8 col2\" >0.8199</td>\n",
       "      <td id=\"T_aafc2_row8_col3\" class=\"data row8 col3\" >0.5646</td>\n",
       "      <td id=\"T_aafc2_row8_col4\" class=\"data row8 col4\" >0.6599</td>\n",
       "      <td id=\"T_aafc2_row8_col5\" class=\"data row8 col5\" >0.6031</td>\n",
       "      <td id=\"T_aafc2_row8_col6\" class=\"data row8 col6\" >0.4209</td>\n",
       "      <td id=\"T_aafc2_row8_col7\" class=\"data row8 col7\" >0.4270</td>\n",
       "      <td id=\"T_aafc2_row8_col8\" class=\"data row8 col8\" >3.6340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aafc2_level0_row9\" class=\"row_heading level0 row9\" >ada</th>\n",
       "      <td id=\"T_aafc2_row9_col0\" class=\"data row9 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_aafc2_row9_col1\" class=\"data row9 col1\" >0.7386</td>\n",
       "      <td id=\"T_aafc2_row9_col2\" class=\"data row9 col2\" >0.7752</td>\n",
       "      <td id=\"T_aafc2_row9_col3\" class=\"data row9 col3\" >0.5712</td>\n",
       "      <td id=\"T_aafc2_row9_col4\" class=\"data row9 col4\" >0.6454</td>\n",
       "      <td id=\"T_aafc2_row9_col5\" class=\"data row9 col5\" >0.5988</td>\n",
       "      <td id=\"T_aafc2_row9_col6\" class=\"data row9 col6\" >0.4077</td>\n",
       "      <td id=\"T_aafc2_row9_col7\" class=\"data row9 col7\" >0.4144</td>\n",
       "      <td id=\"T_aafc2_row9_col8\" class=\"data row9 col8\" >0.2030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aafc2_level0_row10\" class=\"row_heading level0 row10\" >lightgbm</th>\n",
       "      <td id=\"T_aafc2_row10_col0\" class=\"data row10 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_aafc2_row10_col1\" class=\"data row10 col1\" >0.7386</td>\n",
       "      <td id=\"T_aafc2_row10_col2\" class=\"data row10 col2\" >0.7968</td>\n",
       "      <td id=\"T_aafc2_row10_col3\" class=\"data row10 col3\" >0.5646</td>\n",
       "      <td id=\"T_aafc2_row10_col4\" class=\"data row10 col4\" >0.6494</td>\n",
       "      <td id=\"T_aafc2_row10_col5\" class=\"data row10 col5\" >0.5967</td>\n",
       "      <td id=\"T_aafc2_row10_col6\" class=\"data row10 col6\" >0.4059</td>\n",
       "      <td id=\"T_aafc2_row10_col7\" class=\"data row10 col7\" >0.4138</td>\n",
       "      <td id=\"T_aafc2_row10_col8\" class=\"data row10 col8\" >166.3690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aafc2_level0_row11\" class=\"row_heading level0 row11\" >xgboost</th>\n",
       "      <td id=\"T_aafc2_row11_col0\" class=\"data row11 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_aafc2_row11_col1\" class=\"data row11 col1\" >0.7363</td>\n",
       "      <td id=\"T_aafc2_row11_col2\" class=\"data row11 col2\" >0.7820</td>\n",
       "      <td id=\"T_aafc2_row11_col3\" class=\"data row11 col3\" >0.5708</td>\n",
       "      <td id=\"T_aafc2_row11_col4\" class=\"data row11 col4\" >0.6502</td>\n",
       "      <td id=\"T_aafc2_row11_col5\" class=\"data row11 col5\" >0.5991</td>\n",
       "      <td id=\"T_aafc2_row11_col6\" class=\"data row11 col6\" >0.4053</td>\n",
       "      <td id=\"T_aafc2_row11_col7\" class=\"data row11 col7\" >0.4132</td>\n",
       "      <td id=\"T_aafc2_row11_col8\" class=\"data row11 col8\" >0.1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aafc2_level0_row12\" class=\"row_heading level0 row12\" >knn</th>\n",
       "      <td id=\"T_aafc2_row12_col0\" class=\"data row12 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_aafc2_row12_col1\" class=\"data row12 col1\" >0.7167</td>\n",
       "      <td id=\"T_aafc2_row12_col2\" class=\"data row12 col2\" >0.7319</td>\n",
       "      <td id=\"T_aafc2_row12_col3\" class=\"data row12 col3\" >0.4896</td>\n",
       "      <td id=\"T_aafc2_row12_col4\" class=\"data row12 col4\" >0.6183</td>\n",
       "      <td id=\"T_aafc2_row12_col5\" class=\"data row12 col5\" >0.5412</td>\n",
       "      <td id=\"T_aafc2_row12_col6\" class=\"data row12 col6\" >0.3427</td>\n",
       "      <td id=\"T_aafc2_row12_col7\" class=\"data row12 col7\" >0.3498</td>\n",
       "      <td id=\"T_aafc2_row12_col8\" class=\"data row12 col8\" >0.1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aafc2_level0_row13\" class=\"row_heading level0 row13\" >dt</th>\n",
       "      <td id=\"T_aafc2_row13_col0\" class=\"data row13 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_aafc2_row13_col1\" class=\"data row13 col1\" >0.6992</td>\n",
       "      <td id=\"T_aafc2_row13_col2\" class=\"data row13 col2\" >0.6713</td>\n",
       "      <td id=\"T_aafc2_row13_col3\" class=\"data row13 col3\" >0.5783</td>\n",
       "      <td id=\"T_aafc2_row13_col4\" class=\"data row13 col4\" >0.5698</td>\n",
       "      <td id=\"T_aafc2_row13_col5\" class=\"data row13 col5\" >0.5665</td>\n",
       "      <td id=\"T_aafc2_row13_col6\" class=\"data row13 col6\" >0.3395</td>\n",
       "      <td id=\"T_aafc2_row13_col7\" class=\"data row13 col7\" >0.3445</td>\n",
       "      <td id=\"T_aafc2_row13_col8\" class=\"data row13 col8\" >0.1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aafc2_level0_row14\" class=\"row_heading level0 row14\" >dummy</th>\n",
       "      <td id=\"T_aafc2_row14_col0\" class=\"data row14 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_aafc2_row14_col1\" class=\"data row14 col1\" >0.6513</td>\n",
       "      <td id=\"T_aafc2_row14_col2\" class=\"data row14 col2\" >0.5000</td>\n",
       "      <td id=\"T_aafc2_row14_col3\" class=\"data row14 col3\" >0.0000</td>\n",
       "      <td id=\"T_aafc2_row14_col4\" class=\"data row14 col4\" >0.0000</td>\n",
       "      <td id=\"T_aafc2_row14_col5\" class=\"data row14 col5\" >0.0000</td>\n",
       "      <td id=\"T_aafc2_row14_col6\" class=\"data row14 col6\" >0.0000</td>\n",
       "      <td id=\"T_aafc2_row14_col7\" class=\"data row14 col7\" >0.0000</td>\n",
       "      <td id=\"T_aafc2_row14_col8\" class=\"data row14 col8\" >0.2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_aafc2_level0_row15\" class=\"row_heading level0 row15\" >svm</th>\n",
       "      <td id=\"T_aafc2_row15_col0\" class=\"data row15 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_aafc2_row15_col1\" class=\"data row15 col1\" >0.6011</td>\n",
       "      <td id=\"T_aafc2_row15_col2\" class=\"data row15 col2\" >0.0000</td>\n",
       "      <td id=\"T_aafc2_row15_col3\" class=\"data row15 col3\" >0.3033</td>\n",
       "      <td id=\"T_aafc2_row15_col4\" class=\"data row15 col4\" >0.5658</td>\n",
       "      <td id=\"T_aafc2_row15_col5\" class=\"data row15 col5\" >0.2918</td>\n",
       "      <td id=\"T_aafc2_row15_col6\" class=\"data row15 col6\" >0.0815</td>\n",
       "      <td id=\"T_aafc2_row15_col7\" class=\"data row15 col7\" >0.1198</td>\n",
       "      <td id=\"T_aafc2_row15_col8\" class=\"data row15 col8\" >0.1910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fc5cf2471f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# PyCaret 설정\n",
    "clf = setup(data=train, target='Outcome')\n",
    "\n",
    "# 모델 비교 (LightGBM 모델 제외)\n",
    "best_model = compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#변수 중요도 시각화 \n",
    "plot_model(best_model, plot='feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델간 비교\n",
    "pred = predict_model(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "필수 과제는 이제 마무리 되었습니다.\n",
    "\n",
    "PyCaret은 워낙 유명해서 GPT에 넣어도 잘 알려줍니다. \n",
    "\n",
    "GPT, Pycaret 공식 홈페이지의 튜토리얼, 그리고 그동안 배운것을 통해 성능을 자유롭게 개선시켜보세요.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'StratifiedSplit' from 'sklearn.model_selection' (/root/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StratifiedSplit\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'StratifiedSplit' from 'sklearn.model_selection' (/root/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedSplit\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# StratifiedShuffleSplit을 사용하여 데이터를 분할합니다.\n",
    "stratified_shuffle_split = StratifiedSplit(n_splits=20, test_size=0.3, random_state=1)\n",
    "\n",
    "\n",
    "# 데이터 불러오기\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "submit = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "# 훈련 및 테스트 세트 모두에서 'ID' 열을 삭제하세요. 학습에 불필요한 칼럼입니다.\n",
    "train= train.drop(\"ID\",axis=1)\n",
    "test=test.drop(\"ID\",axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# train전처리\n",
    " #1.(스킨를 평균)\n",
    "train.SkinThickness[train.SkinThickness==0]=train.SkinThickness[train.SkinThickness!=0].mean()\n",
    "train.SkinThickness\n",
    " #2.(인슐린를 평균)\n",
    "train.Insulin[train.Insulin==0]=train.Insulin[train.Insulin!=0].mean()\n",
    "train.Insulin\n",
    "\n",
    " #4.(BloodPressure를 정규화)\n",
    "bbb=train.BloodPressure.max()-train.BloodPressure.min()\n",
    "aaa=train.BloodPressure-train.BloodPressure.min()\n",
    "ccc=aaa/bbb\n",
    "train.BloodPressure=ccc\n",
    "\n",
    " #5.(BMI를 정규화)\n",
    "bbb=train.BMI.max()-train.BMI.min()\n",
    "aaa=train.BMI-train.BMI.min()\n",
    "ccc=aaa/bbb\n",
    "train.BMI=ccc\n",
    " #6.(Glucose를 정규화)\n",
    "bbb=train.Glucose.max()-train.Glucose.min()\n",
    "aaa=train.Glucose-train.Glucose.min()\n",
    "ccc=aaa/bbb\n",
    "train.Glucose=ccc\n",
    "\n",
    "#test 전처리\n",
    "#1.(스킨를 평균)\n",
    "test.SkinThickness[test.SkinThickness==0]=test.SkinThickness[test.SkinThickness!=0].mean()\n",
    "test.SkinThickness\n",
    " #2.(인슐린를 평균)\n",
    "test.Insulin[test.Insulin==0]=test.Insulin[test.Insulin!=0].mean()\n",
    "test.Insulin\n",
    "\n",
    " #4.(BloodPressure를 정규화)\n",
    "bbb=test.BloodPressure.max()-test.BloodPressure.min()\n",
    "aaa=test.BloodPressure-test.BloodPressure.min()\n",
    "ccc=aaa/bbb\n",
    "test.BloodPressure=ccc\n",
    "\n",
    " #5.(BMI를 정규화)\n",
    "bbb=test.BMI.max()-test.BMI.min()\n",
    "aaa=test.BMI-test.BMI.min()\n",
    "ccc=aaa/bbb\n",
    "test.BMI=ccc\n",
    " #6.(Glucose를 정규화)\n",
    "bbb=test.Glucose.max()-test.Glucose.min()\n",
    "aaa=test.Glucose-test.Glucose.min()\n",
    "ccc=aaa/bbb\n",
    "test.Glucose=ccc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train set을 독립변수(X)와 종속변수(y)로 나누세요\n",
    "X= train.drop('Outcome',axis=1)\n",
    "y= train['Outcome']\n",
    "# sklearn의 train_test_split을 사용하여 Train set와 Test set으로 분할하세요\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= 0.3 )\n",
    "# 모델 정의 및 학습\n",
    "# sklearn의 RandomForestClassifier를 정의하고 Train set에 대해 학습해세요\n",
    "\n",
    "# 랜덤 포레스트 분류기 생성\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# 모델 훈련\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 세트로 예측\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# 정확도 평가\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "# 모델 평가\n",
    "# sklearn.metrics의 accuracy_score를 사용하여 모델의 성능을 평가하세요\n",
    "\n",
    "\n",
    "scores = cross_val_score(rf_classifier, X, y, cv=stratified_shuffle_split)\n",
    "\n",
    "print(np.round(scores,20))\n",
    "# 모델 예측\n",
    "# Test set에서 예측을 수행하세요\n",
    "y_pred = rf_classifier.predict(test)\n",
    "submit['Outcome'] = y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# test데이터 예측 및 제출\n",
    "# 대회에 결과를 제출하기 위해서 test.csv 데이터에 학습한 모델로 예측을 수행하세요\n",
    "submit.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
